{
  "name": "My workflow Github runner ubuntu Deterministic",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "d7dffd5d-11cd-45e7-861d-6c5a8362ec32",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "861f2bde-c41c-4d9a-8a85-9e32c13c56b6",
      "name": "Webhook - Receive Repo Data",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        -432,
        688
      ],
      "webhookId": "d7dffd5d-11cd-45e7-861d-6c5a8362ec32"
    },
    {
      "parameters": {
        "authentication": "oAuth2",
        "owner": "={{ $json.repoOwner }}",
        "repository": "={{ $json.repositoryName }}",
        "title": "üöÄ ShipIQ: Add {{ $json.fileName }} - DevOps Automation",
        "body": "=## ü§ñ Automated DevOps Enhancement\n\nThis PR was automatically generated by **ShipIQ DevOps Agent** to add missing DevOps infrastructure.\n\n### üìã What's Added:\n- **File**: `{{ $json.fileName }}`\n- **Type**: {{ $json.fileType }}\n- **Language**: {{ $json.language }}\n- **Generated by**: {{ $json.modelUsed }}\n- **Content Length**: {{ $json.contentLength }} characters\n\n### üîç Preview:\n```\n{{ $json.generatedContent.substring(0, 500) }}{{ $json.generatedContent.length > 500 ? '...' : '' }}\n```\n\n### ‚úÖ Ready for Review:\n- [ ] Review generated {{ $json.fileName }}\n- [ ] Test deployment pipeline\n- [ ] Verify functionality\n- [ ] Approve and merge\n\n---\n*Generated by ShipIQ DevOps Agent - Automated DevOps Enhancement Platform*",
        "labels": "{{ $json.fileType }},devops,automated",
        "assignees": []
      },
      "id": "149c9ea0-3968-4359-9526-b1776095ba36",
      "name": "GitHub - Create Issue/PR",
      "type": "n8n-nodes-base.github",
      "typeVersion": 1,
      "position": [
        2432,
        1024
      ],
      "webhookId": "06980fb9-0aa0-4dac-bd61-8ecfc5963848",
      "credentials": {
        "githubOAuth2Api": {
          "id": "3t8t6J3RW25XqNn8",
          "name": "GitHub account"
        }
      }
    },
    {
      "parameters": {
        "amount": 30,
        "unit": "seconds"
      },
      "id": "2a1aeb18-df67-49a4-a77b-8a02a4dca6e7",
      "name": "Wait for GitHub Actions",
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1,
      "position": [
        2640,
        1024
      ],
      "webhookId": "20a76148-4f12-4241-8bc7-97577cee98fb"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoOwner }}/{{ $json.repositoryName }}/actions/runs",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "status",
              "value": "completed"
            },
            {
              "name": "per_page",
              "value": "5"
            }
          ]
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer {{ $credentials.githubApi.accessToken }}"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "id": "915eb7e1-f658-4d68-87b4-7f135a28ce9c",
      "name": "HTTP - Check Actions Status",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2864,
        1024
      ]
    },
    {
      "parameters": {
        "jsCode": "// Analyze GitHub Actions results and determine next steps\nconst actionsData = $input.first().json;\nconst inputData = $('Build Repo Context').first().json;\n\n// Get the most recent workflow run\nconst latestRun = actionsData.workflow_runs?.[0];\n\nif (!latestRun) {\n  return {\n    json: {\n      ...inputData,\n      status: 'no_runs_found',\n      needsRetry: false,\n      error: 'No workflow runs found',\n      action: 'wait_more',\n      lastChecked: new Date().toISOString()\n    }\n  };\n}\n\nconst status = latestRun.conclusion; // success, failure, cancelled, neutral\nconst runId = latestRun.id;\nconst runUrl = latestRun.html_url;\n\n// Determine action based on status\nlet needsRetry = false;\nlet action = 'success';\nlet error = null;\n\nif (status === 'failure') {\n  needsRetry = inputData.attemptNumber < inputData.maxAttempts;\n  action = needsRetry ? 'retry' : 'max_attempts_reached';\n  error = `Workflow run ${runId} failed`;\n} else if (status === 'success') {\n  action = 'success';\n} else if (status === 'cancelled') {\n  needsRetry = inputData.attemptNumber < inputData.maxAttempts;\n  action = needsRetry ? 'retry' : 'cancelled';\n  error = `Workflow run ${runId} was cancelled`;\n} else {\n  action = 'wait_more';\n  error = `Workflow run ${runId} status: ${status}`;\n}\n\nreturn {\n  json: {\n    ...inputData,\n    status,\n    runId,\n    runUrl,\n    needsRetry,\n    action,\n    error,\n    lastChecked: new Date().toISOString()\n  }\n};"
      },
      "id": "59984612-7c2a-413b-ad5f-49df5a76bea8",
      "name": "Analyze Actions Status",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2992,
        656
      ]
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict"
                },
                "conditions": [
                  {
                    "leftValue": "",
                    "rightValue": "",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    }
                  }
                ],
                "combinator": "and"
              }
            }
          ]
        },
        "options": {}
      },
      "id": "b6088b8f-dd07-430a-80a2-558f664fa9a8",
      "name": "Route by Deployment Status",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3,
      "position": [
        3184,
        1024
      ]
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repoOwner }}/{{ $json.repositoryName }}/actions/runs/{{ $json.runId }}/logs",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer {{ $credentials.githubApi.accessToken }}"
            },
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {
          "timeout": 30000
        }
      },
      "id": "d84f0683-6304-4c5c-885c-27e127e754fe",
      "name": "HTTP - Get Workflow Logs",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3392,
        1024
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "Bearer {{ $credentials['Google Gemini (PaLM) Api account'].apiKey }}"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "contents",
              "value": "=[{\n  \"parts\": [{\n    \"text\": \"You are a DevOps expert specializing in deployment troubleshooting and error analysis. Analyze failed deployments and provide improved versions with better error handling. Always respond with ONLY the improved file content, no explanations or markdown formatting.\\n\\nAnalyze this failed GitHub Actions deployment and provide an improved version:\\n\\n**Failed Deployment Details:**\\n- Repository: {{ $json.repositoryName }}\\n- File Type: {{ $json.fileType }}\\n- Language: {{ $json.language }}\\n- Run ID: {{ $json.runId }}\\n- Error: {{ $json.error }}\\n- Attempt Number: {{ $json.attemptNumber }}\\n- Previous Content: {{ $json.generatedContent.slice(0, 1000) }}\\n- Recent Logs: {{ $json.data && $json.data[0] ? $json.data[0].name : 'no_logs_available' }}\\n\\n**Common Issues to Address:**\\n1. Docker build failures (base image, dependencies, permissions)\\n2. Missing environment variables or secrets\\n3. Port conflicts or network issues\\n4. Test failures or linting errors\\n5. Resource constraints (memory, CPU)\\n6. Permission issues or authentication problems\\n7. Path or file structure problems\\n8. Version compatibility issues\\n\\n**Requirements:**\\n1. Analyze the likely cause of failure based on file type and error\\n2. Generate an improved version with:\\n   - Better error handling\\n   - Retry logic for network operations\\n   - Proper resource management\\n   - Enhanced logging and debugging\\n   - Fallback mechanisms\\n   - Health checks\\n3. Include troubleshooting comments\\n4. Optimize for the specific failure scenario\\n\\nGenerate ONLY the improved {{ $json.fileName }} content:\"\n  }]\n}]"
            },
            {
              "name": "generationConfig",
              "value": "={\n  \"temperature\": 0.1,\n  \"maxOutputTokens\": 3500\n}"
            }
          ]
        },
        "options": {
          "timeout": 180000
        }
      },
      "id": "63e669e5-6339-4ad1-a2ca-71357f0e7494",
      "name": "AI - Fix Deployment Issues",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3584,
        1024
      ]
    },
    {
      "parameters": {
        "jsCode": "// Prepare retry attempt with improved content\nconst aiFixResponse = $input.first().json;\nconst originalData = $('Build Repo Context').first().json;\n\n// Extract improved content from Gemini response\nlet improvedContent = '';\nif (aiFixResponse.candidates && aiFixResponse.candidates[0] && aiFixResponse.candidates[0].content && aiFixResponse.candidates[0].content.parts) {\n  improvedContent = aiFixResponse.candidates[0].content.parts[0].text;\n} else if (aiFixResponse.error) {\n  throw new Error(`Gemini API error: ${aiFixResponse.error.message}`);\n} else {\n  throw new Error('Unexpected Gemini response format for retry');\n}\n\n// Clean up the content\nif (improvedContent.includes('```')) {\n  const lines = improvedContent.split('\\n');\n  const startIndex = lines.findIndex(line => line.trim().startsWith('```'));\n  const endIndex = lines.findIndex((line, index) => index > startIndex && line.trim().endsWith('```'));\n  if (startIndex !== -1 && endIndex !== -1) {\n    improvedContent = lines.slice(startIndex + 1, endIndex).join('\\n');\n  }\n}\n\nconst newAttemptNumber = originalData.attemptNumber + 1;\nconst newBranchName = `shipiq-devops-${originalData.fileType}-${originalData.timestamp}-retry-${newAttemptNumber}`;\nconst newCommitMessage = `fix: Improve ${originalData.fileName} - Attempt ${newAttemptNumber} (ShipIQ)`;\n\nreturn {\n  json: {\n    ...originalData,\n    generatedContent: improvedContent.trim(),\n    attemptNumber: newAttemptNumber,\n    branchName: newBranchName,\n    commitMessage: newCommitMessage,\n    isRetry: true,\n    previousAttempt: originalData.attemptNumber,\n    improvementReason: 'AI-generated improvements based on failure analysis',\n    readyForCommit: true,\n    retryTime: new Date().toISOString()\n  }\n};"
      },
      "id": "492c3241-e6d2-4a07-93d0-4632910920c5",
      "name": "Prepare Retry Attempt",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3760,
        1024
      ]
    },
    {
      "parameters": {
        "amount": "={{ Math.min(300, 30 * Math.pow(2, $json.attemptNumber - 1)) }}",
        "unit": "seconds"
      },
      "id": "abfc454b-6b84-4909-a7f8-8fa69e3a9566",
      "name": "Wait Before Retry (Backoff)",
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1,
      "position": [
        3984,
        1024
      ],
      "webhookId": "27eaa2c2-9222-4dbc-a385-e142657e4557"
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={\n  \"success\": true,\n  \"action\": \"{{ $json.action }}\",\n  \"status\": \"{{ $json.status }}\",\n  \"repository\": {\n    \"owner\": \"{{ $json.repoOwner }}\",\n    \"name\": \"{{ $json.repositoryName }}\",\n    \"url\": \"{{ $json.repoUrl }}\"\n  },\n  \"file\": {\n    \"type\": \"{{ $json.fileType }}\",\n    \"name\": \"{{ $json.fileName }}\",\n    \"path\": \"{{ $json.filePath }}\",\n    \"size\": {{ $json.contentLength }}\n  },\n  \"deployment\": {\n    \"status\": \"{{ $json.status }}\",\n    \"runId\": \"{{ $json.runId }}\",\n    \"runUrl\": \"{{ $json.runUrl }}\",\n    \"attempt\": {{ $json.attemptNumber }},\n    \"maxAttempts\": {{ $json.maxAttempts }}\n  },\n  \"timestamp\": \"{{ $json.lastChecked }}\",\n  \"message\": \"Deployment {{ $json.status === 'success' ? 'completed successfully' : $json.status === 'failure' ? 'failed - check run for details' : 'in progress' }}\"\n}",
        "options": {}
      },
      "id": "7c82e457-d30d-4252-9cbb-ddbc30e75906",
      "name": "Respond - Success",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        3328,
        768
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={\n  \"success\": false,\n  \"action\": \"{{ $json.action }}\",\n  \"status\": \"{{ $json.status }}\",\n  \"repository\": {\n    \"owner\": \"{{ $json.repoOwner }}\",\n    \"name\": \"{{ $json.repositoryName }}\",\n    \"url\": \"{{ $json.repoUrl }}\"\n  },\n  \"error\": {\n    \"message\": \"{{ $json.error }}\",\n    \"runId\": \"{{ $json.runId }}\",\n    \"runUrl\": \"{{ $json.runUrl }}\",\n    \"attempts\": {{ $json.attemptNumber }},\n    \"maxAttempts\": {{ $json.maxAttempts }}\n  },\n  \"timestamp\": \"{{ $json.lastChecked }}\",\n  \"message\": \"Deployment failed after {{ $json.attemptNumber }} attempts. Manual intervention required.\"\n}",
        "options": {}
      },
      "id": "b89736f6-8189-4bcc-b15b-bb9ada65bec6",
      "name": "Respond - Max Attempts Reached",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        3312,
        592
      ]
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-2.5-pro",
          "mode": "list",
          "cachedResultName": "models/gemini-2.5-pro"
        },
        "messages": {
          "values": [
            {
              "content": "=You are a DevOps expert. Generate a complete and production-ready Dockerfile for a JavaScript application based on the following data:\n\n{{ JSON.stringify($json) }}"
            }
          ]
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        1280,
        1248
      ],
      "id": "ddc11087-dd09-446e-82f1-bc69179650c5",
      "name": "Dockerfile Generation",
      "credentials": {
        "googlePalmApi": {
          "id": "TopwOMmFdNjgctIz",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-2.5-pro",
          "mode": "list",
          "cachedResultName": "models/gemini-2.5-pro"
        },
        "messages": {
          "values": [
            {
              "content": "=You are a DevOps expert specializing in CI/CD pipelines. Generate robust GitHub Actions workflows with comprehensive error handling and retry logic. Always respond with ONLY the YAML content, no explanations or markdown formatting.\n\nGenerate a GitHub Actions workflow for this {{ $json.language }} application.\n\nRepository: {{ $json.repositoryName }}\nPackage File: {{ $json.manifestFilename }}\nScripts Available: {{ $json.scripts }}\nAttempt: {{ $json.attemptNumber }}\n\nRequirements:\n1. Trigger on push to main and pull requests\n2. Use appriate {{ $json.language }} version (Node 18+ for JS/TS)\n3. Install dependencies using {{ $json.manifestFilename }} with retry logic\n4. Run tests if test script exists with proper error handling\n5. Run build if build script exists\n6. Add comprehensive security scanning\n7. Cache dependencies for faster builds with fallback\n8. Run on ubuntu-latest with matrix strategy if needed\n9. Include deployment status reporting\n10. Add retry mechanisms for flaky operations\n11. Include proper artifact management\n12. Add rollback capabilities\n\nGenerate ONLY the .github/workflows/main.yml content:"
            }
          ]
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        1264,
        1472
      ],
      "id": "0a05a5bb-8b7a-48ab-b94a-45a42ab1e8d4",
      "name": "Configuring CI/CD pipelines",
      "credentials": {
        "googlePalmApi": {
          "id": "TopwOMmFdNjgctIz",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-2.5-pro",
          "mode": "list",
          "cachedResultName": "models/gemini-2.5-pro"
        },
        "messages": {
          "values": [
            {
              "content": "=You are a technical writer and DevOps expert specializing in creating clear and comprehensive documentation for software projects. Always respond with ONLY the Markdown content for the README.md file, with no explanations.\n\nGenerate a professional README.md file for the following application.\n\nProject Name: {{ $json.repositoryName }}\nDescription: {{ $json.description }}\nLanguage: {{ $json.language }}\nRun Command: {{ $json.scripts }}\n\nRequirements:\n1.  Include a main heading with the Project Name.\n2.  Add placeholder badges for build status and license.\n3.  Use the provided Description for an overview section.\n4.  Create a \"Features\" section with a few logical bullet points for this type of application.\n5.  Provide clear \"Installation\" and \"Usage\" sections. The Usage section should detail how to run the project using the provided run command.\n6.  List the primary technologies used.\n\nGenerate ONLY the content for the README.md file."
            }
          ]
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        1248,
        1696
      ],
      "id": "e051c063-52ed-4fbf-a053-04a3a3a73418",
      "name": "Documentation Generator",
      "credentials": {
        "googlePalmApi": {
          "id": "TopwOMmFdNjgctIz",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "d7c9541b-6515-4c92-86db-e6115e777ebc",
              "leftValue": "={{ $json.gapReport }}",
              "rightValue": "={{ $json.gapReport[0] }}",
              "operator": {
                "type": "array",
                "operation": "contains",
                "rightType": "any"
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1024,
        1264
      ],
      "id": "bb76e57e-0c56-455a-ab4e-1cb6ef366c3f",
      "name": "If Dockerfile Missing"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "d8d43089-02c0-4fae-88df-1d2794dac728",
              "leftValue": "={{ $json.gapReport }}",
              "rightValue": "={{ $json.gapReport[1] }}",
              "operator": {
                "type": "array",
                "operation": "contains",
                "rightType": "any"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1040,
        1488
      ],
      "id": "0b39003b-a08f-40b4-8fe4-4f721aaa0496",
      "name": "If CI/CD pipelines absent"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "3cfd33af-4dc8-4aa8-a031-0bb27c5c841e",
              "leftValue": "={{ $json.gapReport }}",
              "rightValue": "={{ $json.gapReport[2] }}",
              "operator": {
                "type": "array",
                "operation": "contains",
                "rightType": "any"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1008,
        1712
      ],
      "id": "ef71bc31-34e2-4d3b-916b-5e0bc54f9ca3",
      "name": "If documentation absent"
    },
    {
      "parameters": {
        "numberInputs": 3
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        2064,
        1376
      ],
      "id": "75fe0e81-2969-40af-b7cb-8bf386715ecd",
      "name": "Merge"
    },
    {
      "parameters": {
        "jsCode": "// Process AI Response\n// Runs once after Aggregate Generated Files outputs allFiles[]\n// Prepares files for GitHub commit safely for all file types\n\nconst baseData = $('Build Repo Context').first().json;\nconst allFiles = $json.allFiles || [];\nconst finalCommits = [];\n\nfor (const generatedFile of allFiles) {\n  let fileContent = '';\n\n  // Handle AI-style content structure\n  if (generatedFile.content?.parts) {\n    fileContent = generatedFile.content.parts\n      .map(p => p.text || '')\n      .join('');\n  } \n  // Handle regular file content\n  else if (generatedFile.fileContent) {\n    fileContent = generatedFile.fileContent;\n  }\n\n  // Clean code fences (```...```) only for non-YAML / non-Docker files\n  const lowerName = generatedFile.fileName?.toLowerCase() || '';\n  const shouldClean =\n    !lowerName.includes('dockerfile') &&\n    !lowerName.endsWith('.yml') &&\n    !lowerName.endsWith('.yaml');\n\n  if (shouldClean && fileContent.includes('```')) {\n    const lines = fileContent.split('\\n');\n    if (\n      lines[0].trim().startsWith('```') &&\n      lines[lines.length - 1].trim().startsWith('```')\n    ) {\n      fileContent = lines.slice(1, -1).join('\\n');\n    }\n  }\n\n  // Create a commit-ready object for each file\n  finalCommits.push({\n    json: {\n      repositoryName: baseData.originalData.repository.name,\n      repoOwner: baseData.originalData.repository.owner,\n      fileName: generatedFile.fileName,\n      fileContent: fileContent.trim(),\n      readyForCommit: true,\n    },\n  });\n}\n\n// Return one item per file ready to commit\nreturn finalCommits;\n"
      },
      "id": "5a2133c8-d23b-412b-b342-c9f2c40f99ee",
      "name": "Process AI Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2096,
        976
      ]
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [
        832,
        1424
      ],
      "id": "51dffc2d-71b3-4374-9de9-53a98af554b2",
      "name": "No Operation, do nothing1"
    },
    {
      "parameters": {
        "url": "=https://api.github.com/repos/{{ $json.repository.owner }}/{{ $json.repository.name }}/git/refs/heads/{{ $json.repository.defaultBranch }}\n",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "application/vnd.github.v3+json"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        224,
        288
      ],
      "id": "398ee928-c0be-4f3f-a193-03499338c002",
      "name": "Get Main Branch SHA",
      "credentials": {
        "httpHeaderAuth": {
          "id": "q0DvGPzZs3wy704Y",
          "name": "Header Auth account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=https://api.github.com/repos/{{ $('Build Repo Context').first().json.repository.owner }}/{{ $('Build Repo Context').first().json.repository.name }}/git/refs\n",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Accept",
              "value": "JSON"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"ref\": \"refs/heads/{{ $('Set Branch Name').first().json.branchName }}\",\n  \"sha\": \"{{ $('Get Main Branch SHA').first().json.object.sha }}\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        448,
        288
      ],
      "id": "3abbaf6b-8393-4012-99ed-e1957977f833",
      "name": "Create the New Branch",
      "credentials": {
        "httpHeaderAuth": {
          "id": "q0DvGPzZs3wy704Y",
          "name": "Header Auth account"
        }
      }
    },
    {
      "parameters": {
        "authentication": "oAuth2",
        "resource": "file",
        "owner": {
          "__rl": true,
          "value": "={{ $json.repoOwner }}\n",
          "mode": ""
        },
        "repository": {
          "__rl": true,
          "value": "={{ $json.repositoryName }}\n",
          "mode": ""
        },
        "filePath": "={{ $json.fileName }}",
        "fileContent": "={{ $json.fileContent }}",
        "commitMessage": "=feat: Add/update {{ $json.fileName }}",
        "additionalParameters": {
          "branch": {
            "branch": "={{ $('Set Branch Name').first().json.branchName }}"
          }
        }
      },
      "id": "7ac04c34-ad4d-432a-a62b-4d2045bc4dae",
      "name": "GitHub - Commit",
      "type": "n8n-nodes-base.github",
      "typeVersion": 1,
      "position": [
        1872,
        704
      ],
      "webhookId": "3882a4db-0fdc-4373-a706-04f1f1375c7d",
      "credentials": {
        "githubOAuth2Api": {
          "id": "3t8t6J3RW25XqNn8",
          "name": "GitHub account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "82c7a51e-0bef-4715-8df9-b05640942457",
              "name": "fileName",
              "value": "README.md",
              "type": "string"
            },
            {
              "id": "554d28f7-2a78-4593-8f50-24eb9f9e4476",
              "name": "fileContent",
              "value": "={{ $json.content.parts[0].text }}",
              "type": "string"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1696,
        1696
      ],
      "id": "053c2c51-ef72-4aa0-a24b-4e0d2e50ec69",
      "name": "Set Node Documentation"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "3a3b07d1-18fd-4e9a-85ed-c4f2116d810e",
              "name": "fileName",
              "value": "Dockerfile",
              "type": "string"
            },
            {
              "id": "0e699a91-cc12-4f33-a51c-017bd8ff0d65",
              "name": "fileContent",
              "value": "={{ $json.content.parts[0].text }}",
              "type": "string"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1744,
        1248
      ],
      "id": "297502fc-b809-4ea3-b499-5299166c6440",
      "name": "Set Node Dockerfile"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "edf58c8f-376a-48b9-95ac-f001445f7a31",
              "name": "fileName",
              "value": ".github/workflows/main.yml",
              "type": "string"
            },
            {
              "id": "56f7f80c-5f7c-43ac-b3df-5b311861d8fb",
              "name": "fileContent",
              "value": "={{ $json.content.parts[0].text }}",
              "type": "string"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1712,
        1472
      ],
      "id": "3f6f82b4-5e6b-4553-b8e6-bb18376148d8",
      "name": "Edit Fields"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "8c1a0811-02ca-4465-b890-4df17e77bfb0",
              "name": "branchName",
              "value": "=shipiq-agent-{{ $now.ts }}",
              "type": "string"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        0,
        288
      ],
      "id": "9ccfa160-5e20-4aeb-b618-5f6b46997326",
      "name": "Set Branch Name"
    },
    {
      "parameters": {
        "jsCode": "// // // This node acts as a synchronization barrier across branches\n// // // Works in n8n v1.113.3 where `this.getWorkflowStaticData()` is unavailable\n\n// // const allInputs = $input.all().map(i => i.json);\n\n// // // Use the global object to simulate temporary in-memory storage\n// // globalThis.__aggregatedFiles__ = globalThis.__aggregatedFiles__ || [];\n\n// // // Add the current branch's file(s)\n// // globalThis.__aggregatedFiles__.push(...allInputs);\n\n// // // Adjust this number to match how many branches you expect\n// // const EXPECTED_FILE_COUNT = 3;\n\n// // // Once all branches have added their outputs, release combined data\n// // if (globalThis.__aggregatedFiles__.length >= EXPECTED_FILE_COUNT) {\n// //   const allFiles = globalThis.__aggregatedFiles__;\n// //   delete globalThis.__aggregatedFiles__; // clear memory\n// //   return [{ json: { allFiles } }];\n// // } else {\n// //   // Hold until other branches finish ‚Äî output nothing yet\n// //   return [];\n// // }\n// // Aggregate Generated Files Node\n// // Works in n8n v1.113.3 - synchronizes parallel branches\n\n// // const allInputs = $input.all().map(i => i.json);\n// // const allFiles = $input.all().map(i => i.json);\n\n// // // Persistent memory across branches during this workflow run\n// // globalThis.__aggregatedFiles__ = globalThis.__aggregatedFiles__ || [];\n\n// // // Add this branch's data\n// // globalThis.__aggregatedFiles__.push(...allInputs);\n\n// // // Number of branches expected (adjust if needed)\n// // const EXPECTED_FILE_COUNT = 3;\n\n// // // Check if all branches have finished\n// // if (globalThis.__aggregatedFiles__.length >= EXPECTED_FILE_COUNT) {\n// //   const allFiles = globalThis.__aggregatedFiles__;\n// //   delete globalThis.__aggregatedFiles__; // clear memory\n\n// //   // Output once with all files combined\n// //   return [{ json: { allFiles, complete: true } }];\n// // } else {\n// //   // Return a passive flag so the workflow doesn't break\n// //   return [{ json: { complete: false }, {\n// //     allFiles,\n// //     complete: true\n// //   } }];\n// // }\n\n\n// // Aggregate Generated Files Node\n// // Combine all items coming from Merge (Append) node into one object\n\n// const allFiles = $input.all().map(i => i.json);\n\n// // Output one combined object with all files\n// return [{\n//   json: {\n//     allFiles,\n//     complete: true\n//   }\n// }];\n\n\n\n// Aggregate Generated Files Node\n// Collects results from multiple branches and waits until all have arrived\n// Works in n8n v1.113.3 (self-hosted) with sandboxed Code node\n\nconst allInputs = $input.all().map(i => i.json);\n\n// Use globalThis to persist partial results between parallel branch executions\nglobalThis.__aggregatedFiles__ = globalThis.__aggregatedFiles__ || [];\n\n// Push the new files from this branch execution\nglobalThis.__aggregatedFiles__.push(...allInputs);\n\n// Define how many files you expect (adjust if needed)\nconst EXPECTED_FILE_COUNT = 3;\n\n// When all expected files have arrived:\nif (globalThis.__aggregatedFiles__.length >= EXPECTED_FILE_COUNT) {\n  const allFiles = globalThis.__aggregatedFiles__;\n  delete globalThis.__aggregatedFiles__; // clear memory for next run\n  \n  // Output a single combined payload for the next node\n  return [{\n    json: {\n      allFiles,\n      complete: true\n    }\n  }];\n} else {\n  // Early branches return \"complete: false\" so workflow continues safely\n  return [{\n    json: {\n      complete: false\n    }\n  }];\n}\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2064,
        1168
      ],
      "id": "9ff85668-29bf-48f8-80b0-23e9c7235ce9",
      "name": "Aggregate Generated Files",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "f88b1bd1-93e0-4de1-9e62-58f95888159a",
              "leftValue": "={{ $json.complete }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        2352,
        1648
      ],
      "id": "4ec247e9-bd48-4a50-8698-fcf72b03c6ff",
      "name": "If"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "a685e850-a04a-4c83-8da0-c5e6f4883e90",
              "name": "complete",
              "value": true,
              "type": "boolean"
            },
            {
              "id": "017b991b-4b74-4e35-a5e0-7be744b5e320",
              "name": "allFiles",
              "value": "={{ $input.all().map(item => item.json) }}",
              "type": "array"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        2048,
        1648
      ],
      "id": "963d7161-d7bf-48a7-b7df-26dd307b8d48",
      "name": "Combine Files for Commit"
    },
    {
      "parameters": {
        "jsCode": "// ===============================\n// Build Repo Context (TRUST BACKEND)\n// ===============================\n\n// 1Ô∏è‚É£ Read webhook payload\nconst payload = $input.first().json.body || $input.first().json;\n\n// 2Ô∏è‚É£ Hard validation\nif (!payload.repository || !payload.scan) {\n  throw new Error('Invalid payload: missing repository or scan data');\n}\n\n// 3Ô∏è‚É£ Pass-through (NO inference)\nreturn {\n  json: {\n    repository: payload.repository,\n    project: payload.project,\n    scan: payload.scan,\n    gapReport: payload.gap_report || payload.scan.gapReport || [],\n    metadata: payload.metadata || {},\n\n    workflow: {\n      attemptNumber: 1,\n      maxAttempts: 3,\n      startedAt: new Date().toISOString()\n    }\n  }\n};\n"
      },
      "id": "cc7c3bd9-3258-4388-afad-8609a5d8382b",
      "name": "Build Repo Context",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -192,
        688
      ]
    },
    {
      "parameters": {
        "jsCode": "// =====================================\n// Rule Engine ‚Äì DevOps Decisions (v1.2.0)\n// =====================================\n\n// 1Ô∏è‚É£ Read normalized context (TRUSTED BACKEND DATA)\nconst context = $input.first().json;\nconst scan = context.scan;\n\n// 2Ô∏è‚É£ Initialize decisions (DEFAULT = false)\nconst decisions = {\n  generateBackendDockerfile: false,\n  generateFrontendDockerfile: false,\n  generateCIWorkflow: false,\n  generateReadme: false,\n  generateTestsConfig: false\n};\n\n// --------------------------------------------------\n// 3Ô∏è‚É£ Dockerfile decisions (IMPORTANT LOGIC)\n// --------------------------------------------------\n\n/**\n * Backend Dockerfile\n * - Backend exists\n * - Node backend\n * - No Dockerfile anywhere in repo\n */\nif (\n  scan.hasBackend &&\n  scan.backendType === 'node' &&\n  !scan.usesDocker\n) {\n  decisions.generateBackendDockerfile = true;\n}\n\n/**\n * Frontend Dockerfile\n * ONLY generate if:\n * - Frontend exists\n * - React frontend\n * - No backend exists (frontend-only app)\n * - No Dockerfile exists\n *\n * (Prevents unnecessary frontend Dockerfiles\n * when backend Dockerfile already covers deployment)\n */\nif (\n  scan.hasFrontend &&\n  scan.frontendType === 'react' &&\n  !scan.hasBackend &&\n  !scan.usesDocker\n) {\n  decisions.generateFrontendDockerfile = true;\n}\n\n// --------------------------------------------------\n// 4Ô∏è‚É£ CI/CD decision\n// --------------------------------------------------\n\n/**\n * Generate CI workflow if GitHub Actions not present\n */\nif (!scan.usesGithubActions) {\n  decisions.generateCIWorkflow = true;\n}\n\n// --------------------------------------------------\n// 5Ô∏è‚É£ README decision\n// --------------------------------------------------\n\nif (!scan.hasReadme) {\n  decisions.generateReadme = true;\n}\n\n// --------------------------------------------------\n// 6Ô∏è‚É£ Test configuration decision\n// --------------------------------------------------\n\nif (!scan.hasTests) {\n  decisions.generateTestsConfig = true;\n}\n\n// --------------------------------------------------\n// 7Ô∏è‚É£ Build execution plan (ORDER MATTERS)\n// --------------------------------------------------\n\nconst executionPlan = [];\n\nif (decisions.generateBackendDockerfile) {\n  executionPlan.push('backend_dockerfile');\n}\n\nif (decisions.generateFrontendDockerfile) {\n  executionPlan.push('frontend_dockerfile');\n}\n\nif (decisions.generateCIWorkflow) {\n  executionPlan.push('ci_workflow');\n}\n\nif (decisions.generateTestsConfig) {\n  executionPlan.push('tests_config');\n}\n\nif (decisions.generateReadme) {\n  executionPlan.push('readme');\n}\n\n// --------------------------------------------------\n// 8Ô∏è‚É£ Final output\n// --------------------------------------------------\n\nreturn {\n  json: {\n    repository: context.repository,\n    project: context.project,\n    scan,\n\n    decisions,\n    executionPlan,\n\n    meta: {\n      decidedAt: new Date().toISOString(),\n      ruleEngineVersion: '1.2.0'\n    }\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        48,
        688
      ],
      "id": "77ed57c8-1428-4cea-b711-5a5783f61998",
      "name": "Rule Engine ‚Äì DevOps Decisions"
    },
    {
      "parameters": {
        "jsCode": "const ctx = $input.first().json;\nconst plan = ctx.executionPlan;\n\nreturn plan.map(step => ({\n  json: {\n    step,\n    context: ctx\n  }\n}));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        272,
        688
      ],
      "id": "2db22e0e-db49-478f-9de4-4efb3a0c4677",
      "name": "Expand Execution Plan"
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 3
                },
                "conditions": [
                  {
                    "leftValue": "={{$json.step}}",
                    "rightValue": "backend_dockerfile",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "6020104d-5d7e-49da-a3ef-dc09a2791fc0"
                  }
                ],
                "combinator": "and"
              }
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 3
                },
                "conditions": [
                  {
                    "id": "4cf57b86-550a-43da-bcae-ef1fe7c17f3e",
                    "leftValue": "={{$json.step}}",
                    "rightValue": "ci_workflow",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              }
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 3
                },
                "conditions": [
                  {
                    "id": "2390aa9e-0874-4697-a70b-5c34a9fc51d9",
                    "leftValue": "={{$json.step}}",
                    "rightValue": "=tests_config",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              }
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.4,
      "position": [
        528,
        688
      ],
      "id": "3ba8034e-9b7e-4cc7-b6e5-e09c1ba43378",
      "name": "Route Execution Step"
    },
    {
      "parameters": {
        "jsCode": "// =====================================\n// Generate Backend Dockerfile (Node.js)\n// Platform-safe v3.3 ‚Äì n8n sandbox compliant\n// =====================================\n\n// 1Ô∏è‚É£ Read routed input\nconst wrapper = $input.first().json;\nconst context = wrapper.context;\n\nif (!context) {\n  throw new Error('Missing context from Route Execution Step');\n}\n\nconst { project, scan } = context;\n\n// 2Ô∏è‚É£ Safety checks\nif (!scan?.hasBackend) {\n  throw new Error('Backend Dockerfile requested but no backend detected');\n}\n\nif (scan.backendType !== 'node') {\n  throw new Error(`Unsupported backend type: ${scan.backendType}`);\n}\n\n// 3Ô∏è‚É£ Resolve backend path\nconst backendPath = scan.backendPath || 'backend/';\n\n// 4Ô∏è‚É£ Resolve start command (STRICTLY from scan/project data)\nlet cmdArray = null;\n\n// Priority 1: explicit scan-provided command (best)\nif (Array.isArray(scan.startCommand)) {\n  cmdArray = scan.startCommand;\n}\n\n// Priority 2: npm start\nelse if (project?.scripts?.start) {\n  cmdArray = ['npm', 'start'];\n}\n\n// Priority 3: scan-provided entry file\nelse if (scan.entryFile) {\n  cmdArray = ['node', scan.entryFile];\n}\n\n// Final fallback: node .\nelse {\n  cmdArray = ['node', '.'];\n}\n\n// 5Ô∏è‚É£ Dockerfile template (exec-form only)\nconst dockerfileContent = `\n# -----------------------------\n# Backend Dockerfile (Node.js)\n# Generated by DevOps Platform\n# -----------------------------\n\nFROM node:18-alpine\n\nWORKDIR /app\n\nENV NODE_ENV=production\nENV PORT=3000\n\n# Copy dependency files first\nCOPY ${backendPath}package*.json ./\n\nRUN npm install --production\n\n# Copy backend source\nCOPY ${backendPath} .\n\nEXPOSE 3000\n\n# Start application (platform-safe)\nCMD ${JSON.stringify(cmdArray)}\n`.trim();\n\n// 6Ô∏è‚É£ Output\nreturn {\n  json: {\n    repository: context.repository,\n    file: {\n      path: `${backendPath}Dockerfile`,\n      content: dockerfileContent\n    },\n    commit: {\n      message: 'feat: add backend Dockerfile (n8n-safe start resolution)'\n    },\n    meta: {\n      generatedAt: new Date().toISOString(),\n      generator: 'backend_dockerfile_template_v3_3'\n    }\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        896,
        496
      ],
      "id": "fc6e88ce-608b-486c-b712-bea42d708265",
      "name": "Generate Backend Dockerfile (Node.js"
    },
    {
      "parameters": {
        "jsCode": "// =====================================\n// Generate CI Workflow (Node.js)\n// ShipIQ v9.8 ‚Äì GitHub-hosted CI (platform-safe Docker validation)\n// ‚úÖ Path-gated execution (workflow-only)\n// ‚úÖ Deterministic ENV_CHECK\n// ‚úÖ Stage-based failure signaling\n// ‚úÖ Dynamic environment binding + production fallback\n// =====================================\n\n// 1Ô∏è‚É£ Read routed input\nconst input = $input.first().json;\n\nif (input.step !== \"ci_workflow\") {\n  throw new Error(`Invalid step routed to CI generator: ${input.step}`);\n}\n\nconst { repository, scan, deployment } = input.context;\n\n// 2Ô∏è‚É£ Safety checks\nif (!repository || !scan) {\n  throw new Error(\"Missing repository or scan context\");\n}\n\n// 3Ô∏è‚É£ Decide working directory\nconst workingDir = scan.hasBackend ? \"backend\" : \".\";\n\n// 4Ô∏è‚É£ Resolve GitHub Environment name (dynamic + fallback)\nconst environmentName = deployment?.environment || \"production\";\n\n// 5Ô∏è‚É£ GitHub SHA (string literal, DO NOT interpolate here)\nconst GITHUB_SHA = \"${{ github.sha }}\";\n\n// 6Ô∏è‚É£ Resolve backend env vars (exclude frontend vars + PORT)\nconst backendEnvVars = Array.isArray(scan.envVars)\n  ? scan.envVars.filter(\n      v => !v.startsWith(\"REACT_APP_\") && v !== \"PORT\"\n    )\n  : [];\n\n// 7Ô∏è‚É£ Docker env injection (runtime only)\nconst dockerEnvLines = backendEnvVars.map(\n  v => `            -e ${v}=\"\\${{ secrets.${v} }}\" \\\\`\n);\n\n// 8Ô∏è‚É£ ENV_CHECK shell checks\nconst envCheckLines = backendEnvVars.map(\n  v => `          if [ -z \"$${v}\" ]; then echo \"‚ùå Missing env var: ${v}\"; missing=1; fi`\n);\n\n// 9Ô∏è‚É£ ENV_CHECK env injection\nconst envInjectionLines = backendEnvVars.map(\n  v => `          ${v}: \\${{ secrets.${v} }}`\n);\n\n// üîü Build workflow\nconst ciWorkflowLines = [\n  \"name: CI Pipeline (Docker Validation)\",\n  \"\",\n  \"on:\",\n  \"  push:\",\n  \"    branches:\",\n  \"      - \\\"**\\\"\",\n  \"    paths:\",\n  \"      - \\\".github/workflows/**\\\"\",\n  \"\",\n  \"jobs:\",\n  \"  docker-validate:\",\n  \"    runs-on: ubuntu-latest\",\n  \"\",\n  \"    environment:\",\n  `      name: ${environmentName}`,\n  \"\",\n  \"    steps:\",\n  \"      - name: Checkout repository\",\n  \"        uses: actions/checkout@v4\",\n  \"\",\n  \"      - name: Setup Node.js\",\n  \"        uses: actions/setup-node@v4\",\n  \"        with:\",\n  \"          node-version: 18\",\n  \"\",\n  \"      - name: Verify package.json exists\",\n  \"        run: |\",\n  \"          echo \\\"::notice::SHIPIQ_STAGE=VERIFY_PACKAGE\\\"\",\n  `          test -f ${workingDir}/package.json || (echo \\\"‚ùå package.json not found in ${workingDir}\\\" && exit 1)`,\n  \"\",\n  \"      - name: Validate environment variable injection\",\n  \"        env:\",\n  ...envInjectionLines,\n  \"        run: |\",\n  \"          echo \\\"::notice::SHIPIQ_STAGE=ENV_CHECK\\\"\",\n  \"          missing=0\",\n  ...envCheckLines,\n  \"          if [ $missing -eq 1 ]; then\",\n  \"            echo \\\"‚ùå One or more required environment variables are missing\\\"\",\n  \"            exit 1\",\n  \"          else\",\n  \"            echo \\\"‚úÖ All required environment variables are present\\\"\",\n  \"          fi\",\n  \"\",\n  \"      - name: Install dependencies\",\n  `        working-directory: ${workingDir}`,\n  \"        run: |\",\n  \"          echo \\\"::notice::SHIPIQ_STAGE=INSTALL_DEPS\\\"\",\n  \"          npm install\",\n  \"\",\n  \"      - name: Run tests (non-blocking)\",\n  `        working-directory: ${workingDir}`,\n  \"        run: |\",\n  \"          echo \\\"::notice::SHIPIQ_STAGE=TEST\\\"\",\n  \"          if npm run | grep -q \\\"test\\\"; then\",\n  \"            npm test || echo \\\"‚ö†Ô∏è Tests failed or not implemented (non-blocking)\\\"\",\n  \"          else\",\n  \"            echo \\\"‚ÑπÔ∏è No test script defined\\\"\",\n  \"          fi\",\n  \"\",\n  \"      - name: Build Docker image\",\n  \"        run: |\",\n  \"          echo \\\"::notice::SHIPIQ_STAGE=DOCKER_BUILD\\\"\",\n  \"          docker build \\\\\",\n  `            -f ${workingDir}/Dockerfile \\\\`,\n  `            -t ci-test:${GITHUB_SHA} \\\\`,\n  \"            .\",\n  \"\",\n  \"      - name: Run Docker container (platform smoke test)\",\n  \"        run: |\",\n  \"          echo \\\"::notice::SHIPIQ_STAGE=DOCKER_RUN\\\"\",\n  \"          docker run -d \\\\\",\n  \"            --name ci-test \\\\\",\n  \"            -e CI=true \\\\\",\n  \"            -e PORT=3001 \\\\\",\n  ...dockerEnvLines,\n  `            ci-test:${GITHUB_SHA}`,\n  \"\",\n  \"      - name: Wait for startup window\",\n  \"        run: |\",\n  \"          echo \\\"::notice::SHIPIQ_STAGE=STARTUP_WAIT\\\"\",\n  \"          sleep 6\",\n  \"\",\n  \"      - name: Verify container is running\",\n  \"        run: |\",\n  \"          echo \\\"::notice::SHIPIQ_STAGE=VERIFY_RUNNING\\\"\",\n  \"          docker ps --filter \\\"name=ci-test\\\" --filter \\\"status=running\\\" | grep ci-test\",\n  \"\",\n  \"      - name: Detect fatal startup errors (log inference)\",\n  \"        run: |\",\n  \"          echo \\\"::notice::SHIPIQ_STAGE=LOG_SCAN\\\"\",\n  \"          if docker logs ci-test | grep -Ei \\\"fatal|uncaught|exception|cannot parse|failed to start\\\"; then\",\n  \"            echo \\\"‚ùå Fatal error detected during container startup\\\"\",\n  \"            exit 1\",\n  \"          else\",\n  \"            echo \\\"‚úÖ No fatal startup errors detected\\\"\",\n  \"          fi\",\n  \"\",\n  \"      - name: Show container logs\",\n  \"        run: docker logs ci-test\",\n  \"\",\n  \"      - name: Stop container\",\n  \"        if: always()\",\n  \"        run: docker rm -f ci-test\"\n];\n\n// üîö Join lines\nconst ciWorkflow = ciWorkflowLines.join(\"\\n\");\n\n// üîö Output\nreturn {\n  json: {\n    repository,\n    file: {\n      path: \".github/workflows/ci.yml\",\n      content: ciWorkflow\n    },\n    commit: {\n      message:\n        \"ci: github-hosted docker validation with path-based execution\"\n    },\n    meta: {\n      generatedAt: new Date().toISOString(),\n      generator: \"ci_workflow_github_hosted_docker_v9_8\"\n    }\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        896,
        704
      ],
      "id": "9c72f6b7-ed29-4903-9bc5-3dde011e0840",
      "name": "Run CI Workflow (Node.js)"
    },
    {
      "parameters": {
        "jsCode": "// =====================================\n// Generate Tests Config (Node.js)\n// =====================================\n\n// 1Ô∏è‚É£ Read routed input\nconst { step, context } = $input.first().json;\n\nif (step !== 'tests_config') {\n  throw new Error(`Invalid step routed to tests generator: ${step}`);\n}\n\nconst { repository, scan } = context;\n\n// 2Ô∏è‚É£ Decide test directory\nconst basePath = scan.hasBackend ? 'backend' : '.';\nconst testDir = `${basePath}/tests`;\n\n// 3Ô∏è‚É£ Sample test (Jest-style but runner-agnostic)\nconst sampleTest = `\ndescribe('Sample Test', () => {\n  it('should pass basic sanity check', () => {\n    expect(true).toBe(true);\n  });\n});\n`.trim();\n\n// 4Ô∏è‚É£ Instructional README for tests (non-destructive)\nconst testReadme = `\n# Tests Setup\n\nThis project includes a basic test configuration to enable CI validation.\n\n## How to run tests\n\n\\`\\`\\`bash\nnpm test\n\\`\\`\\`\n\n## Notes\n- Replace sample tests with real unit/integration tests.\n- CI will fail if tests fail.\n`.trim();\n\n// 5Ô∏è‚É£ Output MULTIPLE FILES (important)\nreturn {\n  json: {\n    repository: context.repository,\n    files: [\n      {\n        path: `${testDir}/sample.test.js`,\n        content: sampleTest\n      },\n      {\n        path: `${testDir}/README.md`,\n        content: testReadme\n      }\n    ],\n    commit: {\n  message: \"chore: add test scaffolding [skip-ci]\"\n}\n,\n    meta: {\n      generatedAt: new Date().toISOString(),\n      generator: 'tests_config_nodejs_v1'\n    }\n  }\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        896,
        896
      ],
      "id": "21ef9c69-232d-419a-85b2-82653f1e47e4",
      "name": "Generate Tests Config (Node.js)"
    },
    {
      "parameters": {
        "numberInputs": 3
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        1200,
        688
      ],
      "id": "cdfaa588-f3dd-4ae8-b77d-e796d64b1bee",
      "name": "Merge1"
    },
    {
      "parameters": {
        "jsCode": "// =====================================\n// Prepare Commit Payload (FINAL)\n// =====================================\n\nconst items = $input.all();\n\nif (!items.length) {\n  throw new Error(\"No generated files received\");\n}\n\n// 1Ô∏è‚É£ Repository context (safe from first item)\nconst repository = items[0].json.repository;\n\nif (!repository?.owner || !repository?.name) {\n  throw new Error(\"Repository context missing from generator outputs\");\n}\n\n// 2Ô∏è‚É£ Collect files from ALL generators\nconst files = [];\n\nfor (const item of items) {\n  if (item.json.file) {\n    files.push(item.json.file);\n  }\n  if (Array.isArray(item.json.files)) {\n    files.push(...item.json.files);\n  }\n}\n\nif (!files.length) {\n  throw new Error(\"No files found to commit\");\n}\n\n// 3Ô∏è‚É£ Build commit message from generators\nconst generators = items\n  .map(i => i.json.meta?.generator)\n  .filter(Boolean);\n\nconst uniqueGenerators = [...new Set(generators)];\n\nconst commitMessage =\n  uniqueGenerators.length > 0\n    ? `feat(devops): add ${uniqueGenerators.join(\", \")}`\n    : \"feat(devops): add DevOps automation files\";\n\n// 4Ô∏è‚É£ Summary (optional but useful)\nconst summary = {\n  filesAdded: files.map(f => f.path),\n  fileCount: files.length,\n  generatedBy: uniqueGenerators,\n  generatedAt: new Date().toISOString()\n};\n\n// 5Ô∏è‚É£ IMPORTANT: return ARRAY (n8n requirement)\nreturn [\n  {\n    json: {\n      repository,\n      files,\n      commitMessage,\n      summary\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1440,
        704
      ],
      "id": "7ebfd67c-66ab-44bf-8b8c-61b5d8417878",
      "name": "Prepare Commit Payload"
    },
    {
      "parameters": {
        "jsCode": "// =====================================\n// Split Files for GitHub Commit\n// =====================================\n\nconst payload = $input.first().json;\n\nconst { repository, files, commitMessage } = payload;\n\nreturn files.map(file => ({\n  json: {\n    repoOwner: repository.owner,\n    repositoryName: repository.name,\n    fileName: file.path,\n    fileContent: file.content,\n    commitMessage\n  }\n}));\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1664,
        704
      ],
      "id": "432d60de-7cb2-450c-be42-ec99e80b5af3",
      "name": "Split Files for Github"
    }
  ],
  "pinData": {},
  "connections": {
    "Webhook - Receive Repo Data": {
      "main": [
        [
          {
            "node": "Build Repo Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GitHub - Create Issue/PR": {
      "main": [
        [
          {
            "node": "Wait for GitHub Actions",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait for GitHub Actions": {
      "main": [
        [
          {
            "node": "HTTP - Check Actions Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP - Check Actions Status": {
      "main": [
        [
          {
            "node": "Analyze Actions Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Analyze Actions Status": {
      "main": [
        [
          {
            "node": "Route by Deployment Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Route by Deployment Status": {
      "main": [
        [
          {
            "node": "Respond - Success",
            "type": "main",
            "index": 0
          },
          {
            "node": "HTTP - Get Workflow Logs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP - Get Workflow Logs": {
      "main": [
        [
          {
            "node": "AI - Fix Deployment Issues",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI - Fix Deployment Issues": {
      "main": [
        [
          {
            "node": "Prepare Retry Attempt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Retry Attempt": {
      "main": [
        [
          {
            "node": "Wait Before Retry (Backoff)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Dockerfile Generation": {
      "main": [
        [
          {
            "node": "Set Node Dockerfile",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Configuring CI/CD pipelines": {
      "main": [
        [
          {
            "node": "Edit Fields",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Documentation Generator": {
      "main": [
        [
          {
            "node": "Set Node Documentation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Dockerfile Missing": {
      "main": [
        [
          {
            "node": "Dockerfile Generation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If CI/CD pipelines absent": {
      "main": [
        [
          {
            "node": "Configuring CI/CD pipelines",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If documentation absent": {
      "main": [
        [
          {
            "node": "Documentation Generator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Combine Files for Commit",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process AI Response": {
      "main": [
        []
      ]
    },
    "No Operation, do nothing1": {
      "main": [
        [
          {
            "node": "If CI/CD pipelines absent",
            "type": "main",
            "index": 0
          },
          {
            "node": "If Dockerfile Missing",
            "type": "main",
            "index": 0
          },
          {
            "node": "If documentation absent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Main Branch SHA": {
      "main": [
        [
          {
            "node": "Create the New Branch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set Node Documentation": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set Node Dockerfile": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set Branch Name": {
      "main": [
        [
          {
            "node": "Get Main Branch SHA",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        []
      ]
    },
    "Combine Files for Commit": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Repo Context": {
      "main": [
        [
          {
            "node": "Set Branch Name",
            "type": "main",
            "index": 0
          },
          {
            "node": "Rule Engine ‚Äì DevOps Decisions",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Rule Engine ‚Äì DevOps Decisions": {
      "main": [
        [
          {
            "node": "Expand Execution Plan",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Expand Execution Plan": {
      "main": [
        [
          {
            "node": "Route Execution Step",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Route Execution Step": {
      "main": [
        [
          {
            "node": "Generate Backend Dockerfile (Node.js",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Run CI Workflow (Node.js)",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Generate Tests Config (Node.js)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Run CI Workflow (Node.js)": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Generate Backend Dockerfile (Node.js": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Tests Config (Node.js)": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Merge1": {
      "main": [
        [
          {
            "node": "Prepare Commit Payload",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GitHub - Commit": {
      "main": [
        []
      ]
    },
    "Prepare Commit Payload": {
      "main": [
        [
          {
            "node": "Split Files for Github",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Files for Github": {
      "main": [
        [
          {
            "node": "GitHub - Commit",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1",
    "availableInMCP": false
  },
  "versionId": "6fee0767-85f3-4be5-baae-6258a0138e54",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "3bb8c1dbdaa993bd386703392d39eb617ee35f53a16b64b65e1401c1aeeec8c0"
  },
  "id": "sdPlD6OmT70cCv0d",
  "tags": []
}